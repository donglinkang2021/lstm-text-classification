{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.submit import create_test_indices\n",
    "create_test_indices(\n",
    "    'data/process/test.txt', \n",
    "    'data/origin/Test.txt', \n",
    "    'data/process/vocab.txt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils.submit import TestNewsDataset, collate_fn_test\n",
    "batch_size = 64\n",
    "test_dataset = TestNewsDataset(\"./data/process/test.txt\")\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, collate_fn=collate_fn_test, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============test_loader =============\n",
      "tensor([[ 197,  241, 1342,  ...,    1,    1,    1],\n",
      "        [ 417,  824,  170,  ...,    1,    1,    1],\n",
      "        [ 248,   41,  167,  ...,    1,    1,    1],\n",
      "        ...,\n",
      "        [   9,  130,   76,  ...,    1,    1,    1],\n",
      "        [ 383,  254,  199,  ...,    1,    1,    1],\n",
      "        [ 901,  336,  156,  ...,    1,    1,    1]])\n",
      "torch.Size([64, 32])\n"
     ]
    }
   ],
   "source": [
    "print('=============test_loader =============')\n",
    "for data in test_loader:\n",
    "    print(data)\n",
    "    print(data.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.rnn import RNN\n",
    "from utils.tokenizer import Vocabulary\n",
    "\n",
    "vocab = Vocabulary.load('./data/process/vocab.txt')\n",
    "label_list=['财经', '彩票', '房产', '股票', '家居', '教育', '科技', '社会', '时尚', '时政', '体育', '星座', '游戏', '娱乐']\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 128\n",
    "hidden_dim = 128\n",
    "num_layers = 1\n",
    "num_classes = len(label_list)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载模型\n",
    "model = RNN(vocab_size, embedding_dim, hidden_dim, num_layers, num_classes)\n",
    "model.load_state_dict(\n",
    "    torch.load(\n",
    "        'rnn.pth',  \n",
    "        map_location=torch.device('cpu')\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将预测结果写入列表中\n",
    "pred_list = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        data = data.to(device)\n",
    "        outputs = model(data)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        pred_list.extend(predicted.cpu().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将预测结果写入文件中\n",
    "with open('./data/result.txt', 'w', encoding='utf-8') as f_result:\n",
    "    for pred in pred_list:\n",
    "        f_result.write(label_list[pred] + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/origin/Test.txt', 'r', encoding='utf-8') as f_test:\n",
    "    test = f_test.readlines()\n",
    "    print(len(test))\n",
    "    for line in test[:10]:\n",
    "        print(line.strip())\n",
    "\n",
    "with open('./data/result.txt', 'r', encoding='utf-8') as f_result:\n",
    "    res = f_result.readlines()\n",
    "    print(len(res))\n",
    "    for line in res[:10]:\n",
    "        print(line.strip())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
